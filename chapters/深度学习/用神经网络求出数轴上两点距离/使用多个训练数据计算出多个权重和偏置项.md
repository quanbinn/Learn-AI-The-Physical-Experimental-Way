# 使用多个训练数据计算出多个权重和偏置项

## 打开实验文件

- 单击右方的[Jupyter Notebook](https://mybinder.org/v2/gh/ipython/ipython-in-depth/master?filepath=binder/Index.ipynb)，稍后在浏览器里会显示Jupyter Notebook的运行环境。
- 在File的第一个下拉菜单“New Notebook” 的右侧箭头处选择“Python 3”，然后会显示一个新的页面
- 把下面的这段python代码拷贝到这个页面“In [ ]:”右侧的空白栏中， 然后单击上方的按键“运行”，然后会显示出相应的图形。

### 简化绝对值函数loss = | - 15w<sub>1</sub> - 5w<sub>2</sub> + b<sub>1</sub> - 10 | 为： loss = 15w<sub>1</sub> + 5w<sub>2</sub> - b<sub>1</sub> + 10 
### 这个问题转化为求函数　y = 15w<sub>1</sub> + 5w<sub>2</sub> - b<sub>1</sub> + 10 接近0的值。 下面就是用梯度下降法通过多种维度找到最接近0的值。

```python
epsilon = 0.005
w1, w2, b1 = 1, 1, 1

# 输入第1条数据

v = 15*w1+5*w2-b1+10
print("第1条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 15
partial_Differ_Of_w2 = 5
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 15*w1+5*w2-b1+10
print("第1条数据点经过梯度下降后的数值是：",v)

# 输入第2条数据

v = 14*w1-3*w2-b1+17
print("第2条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 14
partial_Differ_Of_w2 = -3
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 14*w1-3*w2-b1+17
print("第2条数据点经过梯度下降后的数值是：",v)

# 输入第3条数据

v = 10*w1-0*w2-b1+10
print("第3条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 10
partial_Differ_Of_w2 = 0
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 10*w1-0*w2-b1+10
print("第3条数据点经过梯度下降后的数值是：",v)

# 输入第4条数据

v = 8*w1+15*w2-b1+7
print("第4条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 8
partial_Differ_Of_w2 = 15
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 8*w1+15*w2-b1+7
print("第4条数据点经过梯度下降后的数值是：",v)

# 输入第5条数据

v = 5*w1-25*w2-b1+30
print("第5条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 5
partial_Differ_Of_w2 = -25
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 5*w1-25*w2-b1+30
print("第5条数据点经过梯度下降后的数值是：",v)

# 输入第6条数据

v = 3*w1-20*w2-b1+23
print("第6条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 3
partial_Differ_Of_w2 = -20
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 3*w1-20*w2-b1+23
print("第6条数据点经过梯度下降后的数值是：",v)

# 输入第7条数据

v = 0*w1-15*w2-b1+15
print("第7条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = 0
partial_Differ_Of_w2 = -15
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = 0*w1-15*w2-b1+15
print("第7条数据点经过梯度下降后的数值是：",v)

# 输入第8条数据

v = -5*w1-25*w2-b1+20
print("第8条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = -5
partial_Differ_Of_w2 = -25
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = -5*w1-25*w2-b1+20
print("第8条数据点经过梯度下降后的数值是：",v)

# 输入第9条数据

v = -10*w1+5*w2-b1+15
print("第9条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = -10
partial_Differ_Of_w2 = 5
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = -10*w1+5*w2-b1+15
print("第9条数据点经过梯度下降后的数值是：",v)

# 输入第10条数据

v = -15*w1-12*w2-b1+3
print("第10条数据的输入和输出数值是：",v)

partial_Differ_Of_w1 = -15
partial_Differ_Of_w2 = -12
partial_Differ_Of_b1 = -1

delta_of_w1 = epsilon * partial_Differ_Of_w1
delta_of_w2 = epsilon * partial_Differ_Of_w2
delta_of_b1 = epsilon * partial_Differ_Of_b1 
print(delta_of_w1,delta_of_w2,delta_of_b1)

w1 = w1 - delta_of_w1
w2 = w2 - delta_of_w2
b1 = b1 - delta_of_b1
print(w1,w2,b1)

v = -15*w1-12*w2-b1+3
print("第10条数据点经过梯度下降后的数值是：",v)
```

## 参考文献及资料

1. [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/neural-networks-case-study/)
