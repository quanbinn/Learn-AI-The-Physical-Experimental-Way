# 定义状态和行动并且设定奖励值的大小

## 实验材料

- 长宽高均为2cm的小木头块
- 截面的长宽均为0.5cm的木头条
- 截面的长宽均为1.2cm的木头条
- 长宽高分别为12cm，12cm，3mm的薄木板

## 开始做

### 1. 依据[Q-Learning using Excel](https://people.revoledu.com/kardi/tutorial/ReinforcementLearning/Q-Learning-Excel.htm)中的例子，把5个房间均改造成4.2×3.6的尺寸，草图如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/sketch.jpg)

#### 5个房间分别为A,B,C,D,E,另外加上户外的房间F(户外的空间被算做一个房间），然后用木头片和木头棍制作实体模型，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/model.jpg)

### 2.从状态E行动，转到状态A, 奖励值为0，从状态A行动，转到状态E, 奖励值为0，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/A-E.jpg)

#### 从状态B行动，转到状态F, 奖励值为100，从状态F行动，转到状态B, 奖励值为0，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/B-F.jpg)

#### 从状态D行动，转到状态B, 奖励值为0，从状态B行动，转到状态D, 奖励值为0，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/D-B.jpg)

#### 从状态D行动，转到状态C, 奖励值为0，从状态C行动，转到状态D, 奖励值为0，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/D-C.jpg)

#### 从状态E行动，转到状态D, 奖励值为0，从状态D行动，转到状态E, 奖励值为0，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/E-D.jpg)

#### 从状态E行动，转到状态F, 奖励值为100，从状态F行动，转到状态E, 奖励值为0，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/E-F.jpg)

#### 从状态F行动，转到状态F, 奖励值为100，用木头条表示，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/F-F.jpg)

#### 把上述所有写上奖励值的木头条粘在相应的实体模型里，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/定义状态和行动并且设定奖励值的大小/ABCDEF.jpg)

## 参考文献及资料

1. 维基百科
	- [Q-learning](https://en.wikipedia.org/wiki/Q-learning) 
	- [Markov decision process](https://en.wikipedia.org/wiki/Markov_decision_process) 

1. [Q-Learning using Excel](https://people.revoledu.com/kardi/tutorial/ReinforcementLearning/Q-Learning-Excel.htm)