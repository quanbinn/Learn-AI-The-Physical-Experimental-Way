# 运算过程3

## 开始做

### 1. 计算出从状态D行动到状态C的新的数值，然后用铅笔写在小木块上，随后放在矩阵Ｑ的实体模型里，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/运算过程3/1a1.jpg)

#### 计算出从状态E行动到状态A,从状态B行动到状态D,从状态C行动到状态D,从状态E行动到状态D的新的数值，然后用铅笔写在小木块上，随后放在矩阵Ｑ的实体模型里，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/运算过程3/1a2.jpg)

#### 计算出从状态A行动到状态E,从状态D行动到状态B,从状态D行动到状态E,从状态F行动到状态B,从状态F行动到状态E的新的数值，然后用铅笔写在小木块上，随后放在矩阵Ｑ的实体模型里，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/运算过程3/1a3.jpg)

#### 计算出从状态B行动到状态E,从状态E行动到状态F,从状态F行动到状态F的新的数值，然后用铅笔写在小木块上，随后放在矩阵Ｑ的实体模型里，如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/运算过程3/1a4.jpg)

### 2.单击右方的[QLearningExample](https://github.com/quanbinn/learn-dl-the-experimental-way/blob/master/issues%2Bhistory/excel/QLearningExample.xls)，在打开的网页下方单击“View raw ”，然后浏览器会下载并打开一个Excel文件“QLearningExample.xls”。打开“RL1”sheet, 你会看到运算过程3的结果Q(3)和Q()(Percentage), 分别如下图所示。

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/运算过程3/Q3-1.png)

![](/images/强化学习/基本的时序差分控制方法/Q-learning/经典实验1/运算过程3/Q3-2.png)

## 参考文献及资料

1. 维基百科
	- [Q-learning](https://en.wikipedia.org/wiki/Q-learning) 
	- [Markov decision process](https://en.wikipedia.org/wiki/Markov_decision_process) 

1. [Q-learning using Excel](https://people.revoledu.com/kardi/tutorial/ReinforcementLearning/Q-learning-Excel.htm)